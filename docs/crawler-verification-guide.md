# Crawler Verification Guide

æœ¬æ–‡æ¡£è®°å½•äº†éªŒè¯çˆ¬è™«ç³»ç»Ÿä¿®å¤æ•ˆæœçš„å„ç§æµ‹è¯•å‘½ä»¤å’ŒéªŒè¯æµç¨‹ã€‚

> **æ–‡æ¡£è·¯å¾„**: `docs/crawler-verification-guide.md`  
> **åˆ›å»ºæ—¶é—´**: 2025-09-02  
> **æœ€åæ›´æ–°**: 2025-09-02  
> **é€‚ç”¨ç‰ˆæœ¬**: Scrapy 2.13+

## ğŸ”§ æ ¸å¿ƒç»„ä»¶æµ‹è¯•

### 1. æµ‹è¯•NLP KeywordExtractor
éªŒè¯jiebaåœç”¨è¯è®¾ç½®ä¿®å¤æ˜¯å¦æˆåŠŸï¼š

```bash
uv run python -c "
from src.nlp.extractor import KeywordExtractor
print('æ­£åœ¨æµ‹è¯•NLP KeywordExtractoråˆå§‹åŒ–...')
try:
    extractor = KeywordExtractor()
    print('âœ“ KeywordExtractoråˆå§‹åŒ–æˆåŠŸï¼')
    # æµ‹è¯•å…³é”®è¯æå–
    test_text = 'è¿™æ˜¯ä¸€ä¸ªå…³äºäººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ çš„æµ‹è¯•æ–‡ç« '
    keywords = extractor.extract_keywords(test_text, 5)
    print(f'âœ“ å…³é”®è¯æå–æµ‹è¯•æˆåŠŸ: {keywords}')
except Exception as e:
    print(f'âœ— é”™è¯¯: {e}')
    import traceback
    traceback.print_exc()
"
```

### 2. æµ‹è¯•NLP Pipeline
éªŒè¯å®Œæ•´çš„NLPå¤„ç†ç®¡é“ï¼š

```bash
uv run python -c "
import sys
sys.path.insert(0, '.')
from src.pipelines import NLPPipeline
print('æµ‹è¯•NLP Pipelineåˆå§‹åŒ–...')
try:
    pipeline = NLPPipeline()
    print('âœ“ NLP Pipelineåˆå§‹åŒ–æˆåŠŸï¼')
except Exception as e:
    print(f'âœ— é”™è¯¯: {e}')
    import traceback
    traceback.print_exc()
"
```

## ğŸ•·ï¸ Scrapyç³»ç»Ÿæµ‹è¯•

### 3. Scrapyé…ç½®æ£€æŸ¥
æ£€æŸ¥é¡¹ç›®é…ç½®æ˜¯å¦æ­£ç¡®ï¼š

```bash
uv run scrapy check
```

### 4. åˆ—å‡ºå¯ç”¨çˆ¬è™«
éªŒè¯çˆ¬è™«æ˜¯å¦èƒ½æ­£å¸¸åŠ è½½ï¼š

```bash
uv run scrapy list
```

### 5. æŸ¥çœ‹æœ€æ–°æ—¥å¿—
æ£€æŸ¥æ˜¯å¦è¿˜æœ‰Criticalé”™è¯¯ï¼š

```bash
tail -n 20 /Users/dingmao/dm/code/taiji/crawler/logs/scrapy.log
```

## ğŸš€ å®Œæ•´çˆ¬è™«æµ‹è¯•

### 6. ç®€å•çˆ¬è™«è¿è¡Œæµ‹è¯•
è¿è¡Œä¸€ä¸ªç®€å•çš„æµ‹è¯•çˆ¬å–ï¼ˆå¦‚æœéœ€è¦ï¼‰ï¼š

```bash
# åœ¨macOSä¸Šä½¿ç”¨gtimeoutï¼Œæˆ–è€…ç›´æ¥é™åˆ¶æ¡ç›®æ•°
uv run scrapy crawl general -s CLOSESPIDER_ITEMCOUNT=1 -a start_urls="http://httpbin.org/html"
uv run scrapy crawl general -a start_urls="http://httpbin.org/html"
```

### 7. æ£€æŸ¥çˆ¬è™«è¿›ç¨‹
æŸ¥çœ‹æ˜¯å¦æœ‰çˆ¬è™«è¿›ç¨‹åœ¨è¿è¡Œï¼š

```bash
lsof -i :8000  # æ£€æŸ¥APIæœåŠ¡ç«¯å£
```

## ğŸ“Š ä¿®å¤éªŒè¯æ¸…å•

æ‰§è¡Œä¸Šè¿°å‘½ä»¤åï¼Œç¡®è®¤ä»¥ä¸‹é¡¹ç›®ï¼š

- [ ] KeywordExtractoråˆå§‹åŒ–æ— TypeError
- [ ] NLP Pipelineåˆå§‹åŒ–æˆåŠŸ
- [ ] Scrapyé…ç½®æ£€æŸ¥é€šè¿‡ï¼ˆ0 contractsï¼‰
- [ ] èƒ½æ­£å¸¸åˆ—å‡ºçˆ¬è™«ï¼ˆå¦‚ï¼šgeneralï¼‰
- [ ] æ—¥å¿—ä¸­æ— Criticalé”™è¯¯
- [ ] åªæœ‰è­¦å‘Šçº§åˆ«çš„åºŸå¼ƒæç¤ºï¼ˆå·²ä¿®å¤çš„ä¸å†å‡ºç°ï¼‰

## ğŸ” æ•…éšœæ’é™¤

å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œæ£€æŸ¥ä»¥ä¸‹é¡¹ç›®ï¼š

1. **ç¯å¢ƒå˜é‡**ï¼šç¡®ä¿.envæ–‡ä»¶é…ç½®æ­£ç¡®
2. **æ•°æ®åº“è¿æ¥**ï¼šPostgreSQLå’ŒRedisæ˜¯å¦æ­£åœ¨è¿è¡Œ
3. **ä¾èµ–åŒ…**ï¼šè¿è¡Œ `uv sync` ç¡®ä¿æ‰€æœ‰ä¾èµ–å·²å®‰è£…
4. **æ–‡ä»¶æƒé™**ï¼šç¡®ä¿logsç›®å½•æœ‰å†™å…¥æƒé™

## ğŸ“ ä¿®å¤å†å²

- âœ… ä¿®å¤KeywordExtractorä¸­jiebaåœç”¨è¯è®¾ç½®çš„TypeError
- âœ… æ·»åŠ å¼‚æ­¥process_start()æ–¹æ³•æ›¿ä»£åºŸå¼ƒçš„process_start_requests()
- âœ… å®ç°process_spider_output_async()æ–¹æ³•æ”¯æŒå¼‚æ­¥spiderè¾“å‡º
- âœ… ç§»é™¤åºŸå¼ƒçš„REQUEST_FINGERPRINTER_IMPLEMENTATIONé…ç½®
- âœ… æµ‹è¯•ä¿®å¤æ•ˆæœå¹¶éªŒè¯çˆ¬è™«èƒ½æ­£å¸¸å¯åŠ¨

---
*æ–‡æ¡£åˆ›å»ºæ—¶é—´ï¼š2025-09-02*
*æœ€åä¿®å¤éªŒè¯ï¼š2025-09-02*